{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.initializers import TruncatedNormal\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "\n",
    "from PIL import Image\n",
    "import random\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "\n",
    "def my_seed_everywhere(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    tf.random.set_seed(seed)\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "\n",
    "my_seed_everywhere(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image Model\n",
    "\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.run_functions_eagerly(False)\n",
    "\n",
    "class SAMModel(tf.keras.Model):\n",
    "    def __init__(self, my_model, rho=0.05):\n",
    "        \"\"\"\n",
    "        p, q = 2 for optimal results as suggested in the paper\n",
    "        (Section 2)\n",
    "        \"\"\"\n",
    "        super(SAMModel, self).__init__()\n",
    "        self.my_model = my_model\n",
    "        self.rho = rho\n",
    "\n",
    "    def train_step(self, data):\n",
    "        (text, labels) = data\n",
    "        e_ws = []\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = self.my_model(text)\n",
    "            loss = self.compiled_loss(labels, predictions)\n",
    "        trainable_params = self.my_model.trainable_variables\n",
    "        gradients = tape.gradient(loss, trainable_params)\n",
    "        grad_norm = self._grad_norm(gradients)\n",
    "        scale = self.rho / (grad_norm + 1e-10)\n",
    "\n",
    "        for (grad, param) in zip(gradients, trainable_params):\n",
    "            e_w = grad * scale\n",
    "            param.assign_add(e_w)\n",
    "            e_ws.append(e_w)\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = self.my_model(text)\n",
    "            loss = self.compiled_loss(labels, predictions)    \n",
    "        \n",
    "        sam_gradients = tape.gradient(loss, trainable_params)\n",
    "        for (param, e_w) in zip(trainable_params, e_ws):\n",
    "            param.assign_sub(e_w)\n",
    "        \n",
    "        self.optimizer.apply_gradients(\n",
    "            zip(sam_gradients, trainable_params))\n",
    "        \n",
    "        self.compiled_metrics.update_state(labels, predictions)\n",
    "        return {m.name: m.result() for m in self.metrics}\n",
    "\n",
    "    def test_step(self, data):\n",
    "        (text, labels) = data\n",
    "        predictions = self.my_model(text, training=False)\n",
    "        loss = self.compiled_loss(labels, predictions)\n",
    "        self.compiled_metrics.update_state(labels, predictions)\n",
    "        return {m.name: m.result() for m in self.metrics}\n",
    "\n",
    "    def _grad_norm(self, gradients):\n",
    "        norm = tf.norm(\n",
    "            tf.stack([\n",
    "                tf.norm(grad) for grad in gradients if grad is not None\n",
    "            ])\n",
    "        )\n",
    "        return norm  \n",
    "    \n",
    "    def call(self, inputs):\n",
    "        \"\"\"Forward pass of SAM.\n",
    "        SAM delegates the forward pass call to the wrapped model.\n",
    "        Args:\n",
    "          inputs: Tensor. The model inputs.\n",
    "        Returns:\n",
    "          A Tensor, the outputs of the wrapped model for given `inputs`.\n",
    "        \"\"\"\n",
    "        return self.my_model(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resize, Padding\n",
    "\n",
    "import cv2\n",
    "\n",
    "\n",
    "def padding(img, set_size):\n",
    "\n",
    "    try:\n",
    "        h,w,c = img.shape\n",
    "    except:\n",
    "        print('파일을 확인후 다시 시작하세요.')\n",
    "        raise\n",
    "\n",
    "    if h < w:\n",
    "        new_width = set_size\n",
    "        new_height = int(new_width * (h/w))\n",
    "    else:\n",
    "        new_height = set_size\n",
    "        new_width = int(new_height * (w/h))\n",
    "\n",
    "    if max(h, w) < set_size:\n",
    "        img = cv2.resize(img, (new_width, new_height), cv2.INTER_CUBIC)\n",
    "    else:\n",
    "        img = cv2.resize(img, (new_width, new_height), cv2.INTER_AREA)\n",
    "\n",
    " \n",
    "    try:\n",
    "        h,w,c = img.shape\n",
    "    except:\n",
    "        print('파일을 확인후 다시 시작하세요.')\n",
    "        raise\n",
    "\n",
    "    delta_w = set_size - w\n",
    "    delta_h = set_size - h\n",
    "    top, bottom = delta_h//2, delta_h-(delta_h//2)\n",
    "    left, right = delta_w//2, delta_w-(delta_w//2)\n",
    "\n",
    "    new_img = cv2.copyMakeBorder(img, top, bottom, left, right, cv2.BORDER_CONSTANT, value=[0, 0, 0])\n",
    "\n",
    "    return new_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#생성한 함수를 활용하여 학습데이터 생성\n",
    "\n",
    "IMAGE_SIZE = [224, 224]\n",
    "\n",
    "Train_img_ls = train['img_path'].to_list()\n",
    "Test_Train_img_ls = test['img_path'].to_list()\n",
    "\n",
    "\n",
    "x_train = []\n",
    "\n",
    "for i in tqdm(range(len(Train_img_ls))) :\n",
    "  img = cv2.imread(Train_img_ls[i], cv2.IMREAD_COLOR)\n",
    "  img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "  pad_img = padding(img,IMAGE_SIZE[0])\n",
    "  x_train.append(pad_img)\n",
    " \n",
    "x_train = np.array(x_train)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "x_test = []\n",
    "\n",
    "for i in tqdm(range(len(Test_Train_img_ls))) :\n",
    "  img = cv2.imread(Test_Train_img_ls[i], cv2.IMREAD_COLOR)\n",
    "  img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "  pad_img = padding(img,IMAGE_SIZE[0])\n",
    "  x_test.append(pad_img)\n",
    "\n",
    "x_test = np.array(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "y_train = train['cat3']\n",
    "y_train = encoder.fit_transform(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다른 사전학습 모델로 변경하여 학습 가능\n",
    "\n",
    "pretrained_model = tf.keras.applications.RegNetY120(weights='imagenet', include_top=False ,input_shape=[*IMAGE_SIZE, 3])\n",
    "# pretrained_model = efn.EfficientNetB7(weights='noisy-student', include_top=False ,input_shape=[*IMAGE_SIZE, 3])\n",
    "# pretrained_model = tf.keras.applications.DenseNet201(weights='imagenet', include_top=False ,input_shape=[*IMAGE_SIZE, 3])\n",
    "# pretrained_model = tf.keras.applications.Xception(weights='imagenet', include_top=False ,input_shape=[*IMAGE_SIZE, 3])\n",
    "# pretrained_model = tf.keras.applications.inception_v3.InceptionV3(weights='imagenet', include_top=False ,input_shape=[*IMAGE_SIZE, 3])\n",
    "# pretrained_model = tf.keras.applications.VGG16(weights='imagenet', include_top=False ,input_shape=[*IMAGE_SIZE, 3])\n",
    "# pretrained_model = tf.keras.applications.ResNet50(weights='imagenet', include_top=False ,input_shape=[*IMAGE_SIZE, 3])\n",
    "# pretrained_model = tf.keras.applications.mobilenet.MobileNet(weights='imagenet', include_top=False ,input_shape=[*IMAGE_SIZE, 3])\n",
    "pretrained_model.trainable = False # False = transfer learning, True = fine-tuning\n",
    "\n",
    "\n",
    "len(pretrained_model.layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 모델 학습 함수 생성\n",
    "\n",
    "def train_inference(x_train, y_train, x_test, pretrained_model,open=-50,dim=64,dropout=0.2,optimizer='Adam',epocs=100,batch_size=32,sam=False):\n",
    "    for layer in pretrained_model.layers[:open]:      #전이학습 개방정도\n",
    "        layer.trainable = False\t\n",
    "\n",
    "\n",
    "\n",
    "    model = tf.keras.Sequential([\n",
    "        pretrained_model,\n",
    "        tf.keras.layers.GlobalAveragePooling2D(),\n",
    "        tf.keras.layers.Dense(dim,activation='relu'),          \n",
    "        tf.keras.layers.Dropout(dropout),                   \n",
    "        tf.keras.layers.Dense(128, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    if sam == True :    \n",
    "        model = SAMModel(model)    \n",
    "    model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss = 'sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    "    )\n",
    "    early = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=3,restore_best_weights=True)\n",
    "    model.fit(x_train, y_train, epochs=epocs, batch_size=batch_size, validation_split=0.1,callbacks=[early])\n",
    "\n",
    "    pred = model.predict(x_test, batch_size=batch_size) \n",
    "    \n",
    "    del model\n",
    "    tf.keras.backend.clear_session()\n",
    "\n",
    "    return pred   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Nadam(learning_rate=5e-6)\n",
    "\n",
    "pretrained_model = tf.keras.applications.RegNetY120(weights='imagenet', include_top=False ,input_shape=[*IMAGE_SIZE, 3])\n",
    "pretrained_model.trainable = False\n",
    "pred11 = train_inference(x_train, y_train, x_test, pretrained_model,open=-1,dim=64,dropout=0.2,optimizer=optimizer,epocs=500,batch_size=32,sam=True)\n",
    "\n",
    "\n",
    "pretrained_model = tf.keras.applications.RegNetY120(weights='imagenet', include_top=False ,input_shape=[*IMAGE_SIZE, 3])\n",
    "pretrained_model.trainable = True\n",
    "pred12 = train_inference(x_train, y_train, x_test, pretrained_model,open=-50,dim=128,dropout=0.3,optimizer=optimizer,epocs=500,batch_size=32,sam=False)\n",
    "\n",
    "\n",
    "pretrained_model = tf.keras.applications.RegNetY120(weights='imagenet', include_top=False ,input_shape=[*IMAGE_SIZE, 3])\n",
    "pretrained_model.trainable = True\n",
    "pred13 = train_inference(x_train, y_train, x_test, pretrained_model,open=-100,dim=128,dropout=0.3,optimizer=optimizer,epocs=500,batch_size=32,sam=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mode(list):\n",
    "    count = 0\n",
    "    mode = 0\n",
    "    for x in list: \n",
    "        if list.count(x) > count:\n",
    "            count = list.count(x)\n",
    "            mode = x\n",
    "\n",
    "    return mode\n",
    "\n",
    "\n",
    "\n",
    "pred_ls = []\n",
    "for i in range(len(pred1)):\n",
    "  index = mode([\n",
    "      pred11[i].argmax(),\n",
    "      pred12[i].argmax(),\n",
    "      pred13[i].argmax(),\n",
    "      ])\n",
    "  pred_ls.append(encoder.classes_[index])\n",
    "y_pre2= encoder.transform(pred_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['cat3'] = y_pre2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = test[['id','cat3']]\n",
    "submission.to_csv('submission_image.csv', index=False, encoding='utf-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.0 ('test')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5102cbe6eef775fa675588fc485acc2fa38583d413d40ff78d2cfd2f494b2959"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
