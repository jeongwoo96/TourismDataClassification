{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#증강에 사용할 형용사, 부사, 유의어 모음 불러오기(Google Drive 첨부 - https://drive.google.com/drive/folders/1U6Y6Zv_PxZXsXLgLlgzu6smZ_e_b2mpS?usp=sharing)\n",
    "\n",
    "adj_ls = pd.read_csv('adjective.csv')['adjective'].to_list()\n",
    "ad_ls = pd.read_csv('adverb.csv')['adverb'].to_list() \n",
    "\n",
    "main_token = pd.read_csv('sim_data.csv')['token'].to_list()  \n",
    "sub_token = pd.read_csv('sim_data.csv')['sim_token'].to_list()\n",
    "sim_dic = {}\n",
    "for m, s in zip(main_token,sub_token) :\n",
    "    sim_dic[m] = s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#형용사 증강 : 문장의 명사 앞에 랜덤으로 형용사어 삽입 함수\n",
    "\n",
    "def aug_adj(senten):\n",
    "    tokens = senten.split(' ')\n",
    "\n",
    "\n",
    "    cnt = 0\n",
    "    token_ls = []\n",
    "    for i in range(len(tokens)) :\n",
    "        token = tokens[i]\n",
    "        if token != '' :\n",
    "            if token[-1] == '은' or token[-1] == '는' or token[-1] == '이' or token[-1] == '가' :\n",
    "                cnt +=1\n",
    "                token_ls.append(token)\n",
    "            if token[-1] == '을' or token[-1] == '를' :\n",
    "                cnt +=1\n",
    "                token_ls.append(token)            \n",
    "\n",
    "    if cnt > 0 :\n",
    "        for i in range(random.randint(1,cnt)) :\n",
    "            token_index = random.randint(0,cnt-1)\n",
    "            senten = senten.replace(token_ls[token_index],'{} {}'.format(adj_ls[random.randint(0,len(adj_ls)-1)],token_ls[token_index]))\n",
    "    \n",
    "    return senten      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#부사 증강 : 문장의 동사 앞에 랜덤으로 부사어 삽입 함수\n",
    "def aug_ad(senten):\n",
    "    tokens = senten.split(' ')\n",
    "\n",
    "\n",
    "    cnt = 0\n",
    "    token_ls = []\n",
    "    for i in range(len(tokens)) :\n",
    "        token = tokens[i]\n",
    "        if token != '' : \n",
    "            if token[-1] == '.':\n",
    "                cnt +=1\n",
    "                token_ls.append(token)\n",
    "\n",
    "    if cnt > 0 :\n",
    "        for i in range(random.randint(1,cnt)) :\n",
    "            token_index = random.randint(0,cnt-1)\n",
    "            senten = senten.replace(token_ls[token_index],'{} {}'.format(ad_ls[random.randint(0,len(ad_ls)-1)],token_ls[token_index]))\n",
    "        \n",
    "    return senten  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#유의어 증강 : 문장의 단어들을 유의어로 변경하는 함수\n",
    "def aug_simul(senten):\n",
    "    tokens = senten.split(' ')\n",
    "    cnt = 0\n",
    "    token_ls3 = []\n",
    "    for i in range(len(tokens)) :\n",
    "        token = tokens[i]\n",
    "        if token in sim_dic.keys():\n",
    "            token_ls3.append(token)\n",
    "            cnt += 1\n",
    "\n",
    "    if cnt > 0 :\n",
    "        for i in range(random.randint(1,cnt)) :\n",
    "            token_index = random.randint(0,len(token_ls3)-1)\n",
    "            to_index = tokens.index(token_ls3[token_index])\n",
    "            to_val = sim_dic[tokens[to_index]].split('/')\n",
    "            if len(to_val) > 1 :\n",
    "                tokens[to_index] = to_val[random.randint(0,len(to_val)-1)]\n",
    "            else :\n",
    "                tokens[to_index] = to_val[0]\n",
    "            \n",
    "            token_ls3.pop(token_index)\n",
    "\n",
    "\n",
    "    senten = ' '.join(tokens)\n",
    "    return senten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#이미지 증강\n",
    "\n",
    "\n",
    "def img_aug(img) :\n",
    "    loader_transform1 = transforms.ColorJitter(\n",
    "        brightness=0.6, \n",
    "        contrast=0.6, \n",
    "        saturation=0.6, \n",
    "        hue=0.2\n",
    "        )  \n",
    "    loader_transform2 = transforms.RandomAffine(degrees=90,fillcolor=0)     \n",
    "\n",
    "\n",
    "    imgArray = np.array(img) # 이미지 분석을 위해 배열 전환\n",
    "    img_shape = imgArray.shape\n",
    "    x = int(img_shape[0] * 0.8)\n",
    "    y = int(img_shape[1] * 0.8)\n",
    "    x2 = int(img_shape[0] * 0.4)\n",
    "    y2 = int(img_shape[1] * 0.4)\n",
    "\n",
    "    re_img = loader_transform1(img)\n",
    "    re_img = loader_transform2(re_img)\n",
    "    re_img = transforms.RandomCrop(size=(x,y))(re_img)\n",
    "    re_img\n",
    "\n",
    "    imgArray_aug = np.array(re_img)\n",
    "    indx1 = random.sample(range(x2),2)\n",
    "    indx2 = random.sample(range(y2),2)\n",
    "\n",
    "    length = (np.max(indx1)-np.min(indx1))*(np.max(indx2)-np.min(indx2))*3\n",
    "\n",
    "    imgArray_aug[np.min(indx1):np.max(indx1), np.min(indx2):np.max(indx2), range(3)] = np.random.choice(256, length, replace=True).reshape(((np.max(indx1)-np.min(indx1)),(np.max(indx2)-np.min(indx2)),3))\n",
    "\n",
    "    aug_img = Image.fromarray(imgArray_aug)\n",
    "\n",
    "    return aug_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir('image/val')   #증강 이미지를 저장할 폴더 생성\n",
    "\n",
    "sam_overview = train['overview'].to_list()\n",
    "sam_label = train['cat3'].to_list()\n",
    "sam_img = train['img_path'].to_list()\n",
    "\n",
    "\n",
    "#증강 샘플 1개 생성\n",
    "sample = sam_overview[0]\n",
    "label = sam_label[0]\n",
    "img = Image.open(sam_img[0])\n",
    "\n",
    "new_sample = aug_adj(sample)\n",
    "new_sample = aug_ad(new_sample)\n",
    "new_sample = aug_simul(new_sample)\n",
    "\n",
    "new_img = img_aug(img)\n",
    "save_path = 'image/val/val_1.jpg'\n",
    "new_img.save(save_path,'JPEG')\n",
    "\n",
    "val_set = pd.DataFrame({'img_path' : [save_path], 'overview' : [new_sample], 'cat3' : [label]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#미리 만들어둔 샘플 1개와 concat하여 5000개의 증강데이터 생성\n",
    "for i in range(4999) :\n",
    "    idx = random.randint(0,len(sam_overview)-1)\n",
    "    sample = sam_overview[idx]\n",
    "    label = sam_label[idx]\n",
    "    img = Image.open(sam_img[idx])\n",
    "    \n",
    "\n",
    "    new_sample = aug_adj(sample)\n",
    "    new_sample = aug_ad(new_sample)\n",
    "    new_sample = aug_simul(new_sample)\n",
    "\n",
    "    new_img = img_aug(img)\n",
    "    save_path = 'image/val/val_{}.jpg'.format(i+2)\n",
    "    new_img.save(save_path,'JPEG')\n",
    "\n",
    "    df = pd.DataFrame({'img_path' : [save_path], 'overview' : [new_sample], 'cat3' : [label]})\n",
    "    val_set = pd.concat([val_set,df],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_set.to_csv('val_set.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 텍스트 증강을 통한 샘플 불균형 완화\n",
    "def text_aug(label_ls, train_set, num, adj_aug=True, ad_aug=True, sim_aug=True ):\n",
    "    train = train_set\n",
    "    cnt = 16985\n",
    "    for i in label_ls :\n",
    "        cnt = Counter(train['cat3'])[i]    \n",
    "        if cnt < num :\n",
    "            for j in range(num-cnt):\n",
    "                print(j)\n",
    "                cnt += 1\n",
    "                df = train.loc[(train['cat3'] == i)]\n",
    "                df_ls = df['overview'].to_list()\n",
    "                num = len(df_ls)\n",
    "                idx = random.randint(0, num-1)\n",
    "                sample = df_ls[idx]\n",
    "                if adj_aug == True :\n",
    "                    sample = aug_adj(sample)\n",
    "                if ad_aug == True :\n",
    "                    sample = aug_ad(sample)\n",
    "                if sim_aug == True :\n",
    "                    sample = aug_simul(sample)\n",
    "\n",
    "\n",
    "                df2 = pd.DataFrame({'id' : ['TRAIN_{}'.format(cnt)], 'overview' : [sample], 'cat3' : [i]})\n",
    "                train = pd.concat([train,df2],axis=0)\n",
    "    return train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = train[['id', 'overview','cat3']]\n",
    "label_ls = list(train_set['cat3'].unique())\n",
    "\n",
    "#형용사만 사용 / 최소 50개\n",
    "data1 = text_aug(label_ls,train_set,50,True,False,False)\n",
    "data1.to_csv('train(adj,50).csv', index=False)\n",
    "\n",
    "\n",
    "#부사만 사용 / 최소 50개\n",
    "data2 = text_aug(label_ls,train_set,50,False,True,False)\n",
    "data2.to_csv('train(ad,50).csv', index=False)\n",
    "\n",
    "\n",
    "#유의어만 사용 / 최소 50개\n",
    "data3 = text_aug(label_ls,train_set,50,False,False,True)\n",
    "data3.to_csv('train(sim,50).csv', index=False)\n",
    "\n",
    "\n",
    "#형용사+부사 / 최소 50개\n",
    "data4 = text_aug(label_ls,train_set,50,True,True,False)\n",
    "data4.to_csv('train(adj,ad,50).csv', index=False)\n",
    "\n",
    "\n",
    "#형용사+부사+유의어 / 최소 100개\n",
    "data5 = text_aug(label_ls,train_set,100,True,True,True)\n",
    "data5.to_csv('train(adj,ad,sim,50).csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.0 ('test')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5102cbe6eef775fa675588fc485acc2fa38583d413d40ff78d2cfd2f494b2959"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
